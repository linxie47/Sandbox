From 9d4ac027b8abdef088eb3257afe6fa48adcb1b4a Mon Sep 17 00:00:00 2001
From: Lin Xie <lin.xie@intel.com>
Date: Thu, 11 Jul 2019 15:00:19 +0800
Subject: [PATCH] IE detect filter based on image inference backend.

Change-Id: If4bffa7b36f523a366b8a465701a7259890cd902
---
 configure                                          |   2 +
 libavfilter/Makefile                               |   1 +
 libavfilter/allfilters.c                           |   1 +
 libavfilter/inference.h                            |  53 +----
 libavfilter/inference_backend/ff_base_inference.c  |  10 +
 libavfilter/inference_backend/ff_inference_impl.c  |   5 +-
 libavfilter/inference_backend/ff_pre_proc.c        |  20 +-
 libavfilter/inference_backend/image_inference.h    |   2 +
 libavfilter/inference_backend/logger.c             |   5 +
 libavfilter/inference_backend/logger.h             |   2 +
 .../inference_backend/openvino_image_inference.c   |   1 +
 libavfilter/vf_ie_detect.c                         | 242 +++++++++++++++++++++
 samples/shell-new/object_detect_mobilessd.sh       | 133 +++++++++++
 13 files changed, 417 insertions(+), 60 deletions(-)
 create mode 100644 libavfilter/vf_ie_detect.c
 create mode 100755 samples/shell-new/object_detect_mobilessd.sh

diff --git a/configure b/configure
index 9b49d6c..9ffa42d 100755
--- a/configure
+++ b/configure
@@ -3424,6 +3424,8 @@ inference_detect_filter_select="dnn"
 inference_identify_filter_deps="libinference_engine libjson_c"
 inference_identify_filter_select="dnn"
 inference_metaconvert_filter_deps="libinference_engine libjson_c"
+ie_detect_filter_deps="libinference_engine_c_api libjson_c"
+ie_detect_filter_select="image_inference"
 interlace_filter_deps="gpl"
 kerndeint_filter_deps="gpl"
 ladspa_filter_deps="ladspa libdl"
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 24bb09c..435d4c0 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -272,6 +272,7 @@ OBJS-$(CONFIG_INFERENCE_CLASSIFY_FILTER)     += vf_inference_classify.o
 OBJS-$(CONFIG_INFERENCE_DETECT_FILTER)       += vf_inference_detect.o
 OBJS-$(CONFIG_INFERENCE_IDENTIFY_FILTER)     += vf_inference_identify.o
 OBJS-$(CONFIG_INFERENCE_METACONVERT_FILTER)  += vf_inference_metaconvert.o
+OBJS-$(CONFIG_IE_DETECT_FILTER)              += vf_ie_detect.o
 OBJS-$(CONFIG_INFLATE_FILTER)                += vf_neighbor.o
 OBJS-$(CONFIG_INTERLACE_FILTER)              += vf_tinterlace.o
 OBJS-$(CONFIG_INTERLEAVE_FILTER)             += f_interleave.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 4588c2b..10661e9 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -248,6 +248,7 @@ extern AVFilter ff_vf_inference_classify;
 extern AVFilter ff_vf_inference_detect;
 extern AVFilter ff_vf_inference_identify;
 extern AVFilter ff_vf_inference_metaconvert;
+extern AVFilter ff_vf_ie_detect;
 extern AVFilter ff_vf_inflate;
 extern AVFilter ff_vf_interlace;
 extern AVFilter ff_vf_interleave;
diff --git a/libavfilter/inference.h b/libavfilter/inference.h
index 9f70e38..aef2f47 100644
--- a/libavfilter/inference.h
+++ b/libavfilter/inference.h
@@ -31,11 +31,9 @@
 #endif
 
 #include "dnn_interface.h"
+#include "inference_backend/ff_base_inference.h"
 
 typedef struct _InferenceBaseContext InferenceBaseContext;
-typedef struct _InputPreproc         ModelInputPreproc;
-typedef struct _OutputPostproc       OutputPostproc;
-typedef struct _ModelOutputPostproc  ModelOutputPostproc;
 
 typedef int (*InferencePreProcess)(InferenceBaseContext *base, int index, AVFrame *in, AVFrame **out);
 
@@ -128,28 +126,6 @@ typedef struct VideoPP {
 #endif
 } VideoPP;
 
-struct _InputPreproc {
-    int   color_format;     ///<! input data format
-    char *layer_name;       ///<! layer name of input
-    char *object_class;     ///<! interested object class
-};
-
-struct _OutputPostproc {
-    char  *layer_name;
-    char  *converter;
-    char  *attribute_name;
-    char  *method;
-    double threshold;
-    double tensor2text_scale;
-    int    tensor2text_precision;
-    AVBufferRef *labels;
-};
-
-#define MAX_MODEL_OUTPUT 4
-struct _ModelOutputPostproc {
-    OutputPostproc procs[MAX_MODEL_OUTPUT];
-};
-
 #define MAX_TENSOR_DIM_NUM 4
 typedef struct InferTensorMeta {
     size_t  dim_size;
@@ -163,33 +139,6 @@ typedef struct InferTensorMeta {
     // AVBufferRef *labels;
 } InferTensorMeta;
 
-typedef struct InferDetection {
-    float   x_min;
-    float   y_min;
-    float   x_max;
-    float   y_max;
-    float   confidence;
-    int     label_id;
-    int     object_id;
-    AVBufferRef *label_buf;
-} InferDetection;
-
-/* dynamic bounding boxes array */
-typedef struct BBoxesArray {
-    InferDetection **bbox;
-    int              num;
-} BBoxesArray;
-
-/* dynamic labels array */
-typedef struct LabelsArray {
-    char **label;
-    int    num;
-} LabelsArray;
-
-typedef struct InferDetectionMeta {
-    BBoxesArray *bboxes;
-} InferDetectionMeta;
-
 typedef struct InferClassification {
     int     detect_id;        ///< detected bbox index
     char   *name;             ///< class name, e.g. emotion, age
diff --git a/libavfilter/inference_backend/ff_base_inference.c b/libavfilter/inference_backend/ff_base_inference.c
index 2112f83..86936dc 100644
--- a/libavfilter/inference_backend/ff_base_inference.c
+++ b/libavfilter/inference_backend/ff_base_inference.c
@@ -7,9 +7,17 @@
 #include "ff_base_inference.h"
 #include "ff_inference_impl.h"
 #include "ff_proc_factory.h"
+#include "logger.h"
 #include <libavutil/avassert.h>
 #include <libavutil/mem.h>
 
+static void ff_log_function(int level, const char *file, const char *function, int line, const char *message) {
+    int log_levels[] = {AV_LOG_QUIET, AV_LOG_ERROR, AV_LOG_WARNING, AV_LOG_VERBOSE, AV_LOG_INFO,
+                        AV_LOG_DEBUG, AV_LOG_INFO,  AV_LOG_TRACE,   AV_LOG_PANIC};
+
+    av_log(NULL, log_levels[level], "%s:%i : %s \t %s \n", file, line, function, message);
+}
+
 FFBaseInference *av_base_inference_create(const char *inference_id) {
     FFBaseInference *base_inference = (FFBaseInference *)av_mallocz(sizeof(*base_inference));
 
@@ -36,6 +44,8 @@ int av_base_inference_set_params(FFBaseInference *base, FFInferenceParam *param)
     base->initialized = TRUE;
     base->post_proc = (void *)getPostProcFunctionByName(base->inference_id, base->param.model);
 
+    set_log_function(ff_log_function);
+
     return 0;
 }
 
diff --git a/libavfilter/inference_backend/ff_inference_impl.c b/libavfilter/inference_backend/ff_inference_impl.c
index 7086d86..0460de1 100644
--- a/libavfilter/inference_backend/ff_inference_impl.c
+++ b/libavfilter/inference_backend/ff_inference_impl.c
@@ -102,11 +102,12 @@ static inline int avFormatToFourCC(int format) {
     case AV_PIX_FMT_BGR24:
         VAII_DEBUG("AV_PIX_FMT_BGR24");
         return FOURCC_BGR;
-// #if VA_MAJOR_VERSION >= 1
+    case AV_PIX_FMT_RGBP:
+        VAII_DEBUG("AV_PIX_FMT_RGBP");
+        return FOURCC_RGBP;
     case AV_PIX_FMT_YUV420P:
         VAII_DEBUG("AV_PIX_FMT_YUV420P");
         return FOURCC_I420;
-// #endif
     }
 
     av_log(NULL, AV_LOG_ERROR, "Unsupported AV Format: %d.", format);
diff --git a/libavfilter/inference_backend/ff_pre_proc.c b/libavfilter/inference_backend/ff_pre_proc.c
index fb3f95f..3d2a95d 100644
--- a/libavfilter/inference_backend/ff_pre_proc.c
+++ b/libavfilter/inference_backend/ff_pre_proc.c
@@ -51,6 +51,8 @@ static inline enum AVPixelFormat FOURCC2FFmpegFormat(int format) {
         return AV_PIX_FMT_BGRA;
     case FOURCC_BGR:
         return AV_PIX_FMT_BGR24;
+    case FOURCC_RGBP:
+        return AV_PIX_FMT_RGBP;
     case FOURCC_I420:
         return AV_PIX_FMT_YUV420P;
     }
@@ -70,17 +72,23 @@ static void FFPreProcConvert(PreProcContext *context, const Image *src, Image *d
     if (src->format == dst->format && src->format == FOURCC_RGBP && src->width == dst->width &&
         src->height == dst->height) {
         int planes_count = GetPlanesCount(src->format);
+        // RGB->BGR
+        Image src_bgr = *src;
+        src_bgr.planes[0] = src->planes[2];
+        src_bgr.planes[2] = src->planes[0];
         for (int i = 0; i < planes_count; i++) {
-            if (src->width == src->stride[i]) {
-                memcpy(dst->planes[i], src->planes[i], src->width * src->height * sizeof(uint8_t));
+            if (src_bgr.width == src_bgr.stride[i]) {
+                memcpy(dst->planes[i], src_bgr.planes[i], src_bgr.width * src_bgr.height * sizeof(uint8_t));
             } else {
-                int dst_stride = src->width * sizeof(uint8_t);
-                int src_stride = src->stride[i] * sizeof(uint8_t);
-                for (int r = 0; r < src->height; r++) {
-                    memcpy(dst->planes[i] + r * dst_stride, src->planes[i] + r * src_stride, dst_stride);
+                int dst_stride = dst->stride[i] * sizeof(uint8_t);
+                int src_stride = src_bgr.stride[i] * sizeof(uint8_t);
+                for (int r = 0; r < src_bgr.height; r++) {
+                    memcpy(dst->planes[i] + r * dst_stride, src_bgr.planes[i] + r * src_stride, dst->width);
                 }
             }
         }
+
+        return;
     }
 
     sws_context = sws_getCachedContext(sws_context, src->width, src->height, FOURCC2FFmpegFormat(src->format),
diff --git a/libavfilter/inference_backend/image_inference.h b/libavfilter/inference_backend/image_inference.h
index 628c54e..bf349c0 100644
--- a/libavfilter/inference_backend/image_inference.h
+++ b/libavfilter/inference_backend/image_inference.h
@@ -113,10 +113,12 @@ struct OutputBlobArray {
 #define __CONFIG_KEY(name) KEY_##name
 #define __DECLARE_CONFIG_KEY(name) static const char *__CONFIG_KEY(name) = __STRING(name)
 __DECLARE_CONFIG_KEY(CPU_EXTENSION);          // library with implementation of custom layers
+__DECLARE_CONFIG_KEY(CPU_THREADS_NUM);        // threads number CPU plugin use for inference
 __DECLARE_CONFIG_KEY(CPU_THROUGHPUT_STREAMS); // number inference requests running in parallel
 __DECLARE_CONFIG_KEY(RESIZE_BY_INFERENCE);    // experimental, don't use
 #else
 #define KEY_CPU_EXTENSION __STRING(CPU_EXTENSION)                   // library with implementation of custom layers
+#define KEY_CPU_THREADS_NUM __STRING(CPU_THREADS_NUM)               // threads number CPU plugin use for inference
 #define KEY_CPU_THROUGHPUT_STREAMS __STRING(CPU_THROUGHPUT_STREAMS) // number inference requests running in parallel
 #define KEY_RESIZE_BY_INFERENCE __STRING(RESIZE_BY_INFERENCE)       // experimental, don't use
 #endif
diff --git a/libavfilter/inference_backend/logger.c b/libavfilter/inference_backend/logger.c
index 96c6600..9118863 100644
--- a/libavfilter/inference_backend/logger.c
+++ b/libavfilter/inference_backend/logger.c
@@ -9,11 +9,16 @@
 #include <string.h>
 
 static VAIILogFuncPtr inference_log_function = NULL;
+static int inference_log_level = VAII_INFO_LOG_LEVEL;
 
 void set_log_function(VAIILogFuncPtr log_func) {
     inference_log_function = log_func;
 };
 
+void set_log_level(int level) {
+    inference_log_level = level;
+};
+
 void debug_log(int level, const char *file, const char *function, int line, const char *message) {
     if (!inference_log_function) {
         set_log_function(default_log_function);
diff --git a/libavfilter/inference_backend/logger.h b/libavfilter/inference_backend/logger.h
index 616088d..0cfafb9 100644
--- a/libavfilter/inference_backend/logger.h
+++ b/libavfilter/inference_backend/logger.h
@@ -32,6 +32,8 @@ typedef void (*VAIILogFuncPtr)(int level, const char *file, const char *function
 
 void set_log_function(VAIILogFuncPtr log_func);
 
+void set_log_level(int level);
+
 void debug_log(int level, const char *file, const char *function, int line, const char *message);
 
 void default_log_function(int level, const char *file, const char *function, int line, const char *message);
diff --git a/libavfilter/inference_backend/openvino_image_inference.c b/libavfilter/inference_backend/openvino_image_inference.c
index 1d7c384..433a46e 100644
--- a/libavfilter/inference_backend/openvino_image_inference.c
+++ b/libavfilter/inference_backend/openvino_image_inference.c
@@ -170,6 +170,7 @@ static int OpenVINOImageInferenceCreate(ImageInferenceContext *ctx, MemoryType t
     if (configs) {
         const char *resize_by_vino = NULL;
         ie_plugin_set_config(vino->plugin, configs);
+        // printf("KEY_CPU_THREADS_NUM:%s\n", ie_plugin_get_config(vino->plugin, KEY_CPU_THREADS_NUM));
         // printf("KEY_CPU_THROUGHPUT_STREAMS:%s\n", ie_plugin_get_config(vino->plugin, KEY_CPU_THROUGHPUT_STREAMS));
         resize_by_vino = ie_plugin_get_config(vino->plugin, KEY_RESIZE_BY_INFERENCE);
         vino->resize_by_inference = (resize_by_vino && !strcmp(resize_by_vino, "TRUE")) ? 1 : 0;
diff --git a/libavfilter/vf_ie_detect.c b/libavfilter/vf_ie_detect.c
new file mode 100644
index 0000000..f606340
--- /dev/null
+++ b/libavfilter/vf_ie_detect.c
@@ -0,0 +1,242 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * image inference filter used for object detection
+ */
+
+#include "libavutil/opt.h"
+#include "libavutil/mem.h"
+#include "libavutil/eval.h"
+#include "libavutil/avassert.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/mathematics.h"
+
+#include "formats.h"
+#include "internal.h"
+#include "avfilter.h"
+#include "filters.h"
+#include "libavcodec/avcodec.h"
+#include "libavformat/avformat.h"
+#include "libswscale/swscale.h"
+#include "libavutil/time.h"
+
+#include "inference.h"
+#include "inference_backend/ff_base_inference.h"
+
+
+#define OFFSET(x) offsetof(IEDetectContext, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
+
+typedef struct IEDetectContext {
+    const AVClass *class;
+
+    FFBaseInference *base;
+
+    FF_INFERENCE_OPTIONS
+
+    int    backend_type;
+
+    void  *proc_config;
+    ModelInputPreproc   model_preproc;
+    ModelOutputPostproc model_postproc;
+} IEDetectContext;
+
+static int query_formats(AVFilterContext *context)
+{
+    AVFilterFormats *formats_list;
+    const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_YUV420P,
+        AV_PIX_FMT_BGR24,    AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_BGR0,     AV_PIX_FMT_RGBP,
+        AV_PIX_FMT_BGRA,     AV_PIX_FMT_VAAPI,
+        AV_PIX_FMT_NONE};
+
+    formats_list = ff_make_format_list(pixel_formats);
+    if (!formats_list) {
+        av_log(context, AV_LOG_ERROR, "Could not create formats list\n");
+        return AVERROR(ENOMEM);
+    }
+
+    return ff_set_common_formats(context, formats_list);
+}
+
+static av_cold int detect_init(AVFilterContext *ctx)
+{
+    int ret = 0;
+    IEDetectContext *s = ctx->priv;
+    FFInferenceParam param = { };
+
+    av_assert0(s->model);
+
+    param.model           = s->model;
+    param.device          = s->device;
+    param.nireq           = s->nireq;
+    param.batch_size      = s->batch_size;
+    param.every_nth_frame = s->every_nth_frame;
+    param.threshold       = s->threshold;
+    param.is_full_frame   = 1;
+
+    // Parse model process configuration
+    if (s->model_proc) {
+        void *proc = ff_read_model_proc(s->model_proc);
+        if (!proc) {
+            av_log(ctx, AV_LOG_ERROR, "Could not read proc config file:"
+                    "%s\n", s->model_proc);
+            return AVERROR(EIO);
+        }
+
+        if (ff_parse_input_preproc(proc, &s->model_preproc) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Parse input preproc error.\n");
+            return AVERROR(EIO);
+        }
+
+        if (ff_parse_output_postproc(proc, &s->model_postproc) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Parse output postproc error.\n");
+            return AVERROR(EIO);
+        }
+
+        s->proc_config = proc;
+        param.model_preproc  = &s->model_preproc;
+        param.model_postproc = &s->model_postproc;
+    }
+
+    s->base = av_base_inference_create(ctx->filter->name);
+    if (!s->base) {
+        av_log(ctx, AV_LOG_ERROR, "Could not create inference.\n");
+        return AVERROR(EINVAL);
+    }
+
+    ret = av_base_inference_set_params(s->base, &param);
+
+    return ret;
+}
+
+static av_cold void detect_uninit(AVFilterContext *ctx)
+{
+    IEDetectContext *s = ctx->priv;
+
+    av_base_inference_release(s->base);
+
+    ff_release_model_proc(s->proc_config, &s->model_preproc, &s->model_postproc);
+}
+
+static int flush_frame(AVFilterLink *outlink, int64_t pts, int64_t *out_pts)
+{
+    AVFilterContext *ctx = outlink->src;
+    IEDetectContext *s = ctx->priv;
+    int ret = 0;
+
+    while (!av_base_inference_frame_queue_empty(ctx, s->base)) {
+        AVFrame *output = NULL;
+        av_base_inference_get_frame(ctx, s->base, &output);
+        if (output) {
+            ret = ff_filter_frame(outlink, output);
+            *out_pts = output->pts + pts;
+        }
+
+        av_base_inference_send_event(ctx, s->base, INFERENCE_EVENT_EOS);
+        av_usleep(5000);
+    }
+
+    return ret;
+}
+
+static int activate(AVFilterContext *ctx)
+{
+    AVFilterLink *inlink = ctx->inputs[0];
+    AVFilterLink *outlink = ctx->outputs[0];
+    IEDetectContext *s = ctx->priv;
+    AVFrame *in = NULL, *output = NULL;
+    int64_t pts;
+    int ret, status;
+
+    FF_FILTER_FORWARD_STATUS_BACK(outlink, inlink);
+
+    ret = ff_inlink_consume_frame(inlink, &in);
+    if (ret < 0)
+        return ret;
+    if (ret > 0)
+        av_base_inference_send_frame(ctx, s->base, in);
+
+    av_base_inference_get_frame(ctx, s->base, &output);
+    if (output)
+        return ff_filter_frame(outlink, output);
+
+    if (ff_inlink_acknowledge_status(inlink, &status, &pts)) {
+        if (status == AVERROR_EOF) {
+            int64_t out_pts = pts;
+
+            ret = flush_frame(outlink, pts, &out_pts);
+            ff_outlink_set_status(outlink, status, out_pts);
+            return ret;
+        }
+    }
+
+    FF_FILTER_FORWARD_WANTED(outlink, inlink);
+
+    return FFERROR_NOT_READY;
+}
+
+static const AVOption ie_detect_options[] = {
+    { "dnn_backend",  "DNN backend for model execution", OFFSET(backend_type),    AV_OPT_TYPE_FLAGS,  { .i64 = 1},          0, 2,  FLAGS },
+    { "model",        "path to model file for network",  OFFSET(model),           AV_OPT_TYPE_STRING, { .str = NULL},       0, 0,  FLAGS },
+    { "model_proc",   "model preproc and postproc",      OFFSET(model_proc),      AV_OPT_TYPE_STRING, { .str = NULL},       0, 0,  FLAGS },
+    { "object_class", "objective class",                 OFFSET(object_class),    AV_OPT_TYPE_STRING, { .str = NULL},       0, 0,  FLAGS },
+    { "device",       "running on device name",          OFFSET(device),          AV_OPT_TYPE_STRING, { .str = NULL},       0, 0,  FLAGS },
+    { "configs",      "configurations to backend",       OFFSET(infer_config),    AV_OPT_TYPE_STRING, { .str = NULL},       0, 0,  FLAGS },
+    { "interval",     "detect every Nth frame",          OFFSET(every_nth_frame), AV_OPT_TYPE_INT,    { .i64 = 1 },  1, 1024, FLAGS},
+    { "nireq",        "inference request number",        OFFSET(nireq),           AV_OPT_TYPE_INT,    { .i64 = 1 },  1, 128,  FLAGS},
+    { "batch_size",   "batch size per infer",            OFFSET(batch_size),      AV_OPT_TYPE_INT,    { .i64 = 1 },  1, 1000, FLAGS},
+    { "threshold",    "threshod to filter output data",  OFFSET(threshold),       AV_OPT_TYPE_FLOAT,  { .dbl = 0.5}, 0, 1,    FLAGS},
+
+    { NULL }
+};
+
+AVFILTER_DEFINE_CLASS(ie_detect);
+
+static const AVFilterPad detect_inputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+static const AVFilterPad detect_outputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_ie_detect = {
+    .name          = "ie_detect",
+    .description   = NULL_IF_CONFIG_SMALL("Image Inference Detect Filter."),
+    .priv_size     = sizeof(IEDetectContext),
+    .query_formats = query_formats,
+    .activate      = activate,
+    .init          = detect_init,
+    .uninit        = detect_uninit,
+    .inputs        = detect_inputs,
+    .outputs       = detect_outputs,
+    .priv_class    = &ie_detect_class,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/samples/shell-new/object_detect_mobilessd.sh b/samples/shell-new/object_detect_mobilessd.sh
new file mode 100755
index 0000000..9c87072
--- /dev/null
+++ b/samples/shell-new/object_detect_mobilessd.sh
@@ -0,0 +1,133 @@
+#!/bin/bash
+
+set -e
+
+if [ -z ${MODELS_PATH} ]; then
+    echo "please set MODELS_PATH. e.g: export MODELS_PATH=/home/media/workspace/tests"
+    exit 1
+fi
+
+BASEDIR=$(dirname "$0")/../..
+usage="$(basename "$0") [-i <stream>] [-options] -- program to do object detection
+
+where:
+-h            show this help text
+-a            use hardware decode to accelerate
+-i  <stream>  set the stream path
+-s            to show on the screen
+-v            to show debug log
+-r  <number>  set inference request number
+-b  <number>  set batch size
+-d  <devices> set devices for each model(C-CPU G-GPU V-VPU H-HDDL) e.g.CGV"
+
+if [ -z "$1" ]; then
+    echo "$usage"
+    exit
+fi
+
+while getopts ':ab:hi:r:svd:' option; do
+    case "$option" in
+        h) echo "$usage"
+            exit
+            ;;
+        a) hw_accel="-flags unaligned -hwaccel vaapi -hwaccel_output_format vaapi -extra_hw_frames 32 -hwaccel_device /dev/dri/renderD128"
+           hw_dl="scale_vaapi=300:300:rgbp,hwdownload,format=rgbp,"
+            ;;
+        i) stream=$OPTARG
+            ;;
+        s) show="true"
+            ;;
+        v) debug_log="-loglevel debug"
+            ;;
+        d) devices_pattern=$OPTARG
+            ;;
+        r) req_num=$OPTARG
+            ;;
+        b) batch=$OPTARG
+            ;;
+        \?) printf "illegal option: -%s\n" "$OPTARG" >&2
+            echo "$usage" >&2
+            exit 1
+            ;;
+        *)
+    esac
+done
+shift $((OPTIND - 1))
+
+MODEL=mobilenet-ssd
+
+CPU="CPU"
+GPU="GPU"
+VPU="MYRIAD"
+HDDL="HDDL"
+GET_DEVICE_ID() {
+    case $1 in
+        C)   echo $CPU;;
+        G)   echo $GPU;;
+        V)   echo $VPU;;
+        H)   echo $HDDL;;
+        *)   echo Unknown device: $1
+        ;;
+    esac
+}
+
+PRECISION_FP16="\"FP16\""
+PRECISION_FP32="\"FP32\""
+GET_PRECISION() {
+    if [ -z $1 ];then
+        exit 0
+    fi
+    case $1 in
+        C)   echo $PRECISION_FP32;;
+        G)   echo $PRECISION_FP16;;
+        V)   echo $PRECISION_FP16;;
+        H)   echo $PRECISION_FP16;;
+        *)   echo Unknown device: $1
+        ;;
+    esac
+}
+
+if [ ! -z "$devices_pattern" ]; then
+    DEVICE1=$(echo "${devices_pattern:0:1}")
+    D_ID1=$(GET_DEVICE_ID $DEVICE1)
+fi
+D_ID1=${D_ID1:-$CPU}
+
+GET_MODEL_PATH() {
+    for path in ${MODELS_PATH//:/ }; do
+        paths=$(find $path -name "$1*.xml" -print)
+        if [ ! -z "$paths" ];
+        then
+            PRECISION=${2:-\"FP32\"}
+            echo $(grep -l "precision=$PRECISION" $paths)
+            exit 0
+        fi
+    done
+    echo -e "\e[31mModel $1.xml file was not found. Please set MODELS_PATH\e[0m" 1>&2
+    exit 1
+}
+
+DETECT_MODEL_PATH=$(GET_MODEL_PATH $MODEL $(GET_PRECISION $DEVICE1))
+
+echo "$DETECT_MODEL_PATH"
+
+PROC_PATH() {
+    echo ${BASEDIR}/samples/model_proc/$1.json
+}
+
+req_num=${req_num:-4}
+batch=${batch:-1}
+
+cfg_string="CPU_THROUGHPUT_STREAMS=8\,CPU_THREADS_NUM=8"
+
+if [ ! -z "$show" ]; then
+    $BASEDIR/ffplay $debug_log -i $stream -sync video -vf \
+        "ie_detect=model=$DETECT_MODEL_PATH:device=$D_ID1:nireq=$req_num:batch_size=$batch, \
+        ocv_overlay"
+else
+    #gdb --args \
+    $BASEDIR/ffmpeg_g $debug_log $hw_accel -i $stream -vf \
+    "${hw_dl}ie_detect=model=$DETECT_MODEL_PATH:model_proc=$(PROC_PATH $MODEL):device=$D_ID1:nireq=$req_num:batch_size=$batch:configs=$cfg_string" \
+        -y -f null - #iemetadata /tmp/obj_detect.json
+fi
+
-- 
2.7.4

